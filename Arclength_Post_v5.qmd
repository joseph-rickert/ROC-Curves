---
title: "Arc Length and Differential Geometry"
subtitle: ""
author: Joseph Rickert
date: Decemvwe 1, 2025
bibliography: references.bib
format: html
---

This post is an attempt to introduce some basic differential geometry into the analysis of ROC curves. I'll try to describe on an intuitive level why it might make sense to use some of what the mathematics know about plane curves to extract more information from ROC curve than most machine learning analyses attempt. The fundamental insight is that using the tools of functional analysis to smooth stair step ROC curves makes these new functional object available for study with the tools of calculus. For most of the useful ROC curves that you are likely to find in the wild it should be obvious that the smooth curves will track the stair-step curves rather closely and that the Area Under the Curve (AUC) of the smoothed and raw curves are within a few decimal points. The first insight from differential geometry comes from realizing that it is meaningful to compute arc length for the smoothed curves. Arc length is really not a meaningful concept for the star-step ROC curves since any stair-step curve that goes from (0,0) to (1,1) will have a length of 2. Before I describe the merits of arc length and how the concept of curvature may be helpful in studying ROC curves I describe how you can use the code in this post.


## The code in this post

The intention of this post is to provide the beginnings of a laboratory for studying ROC curves built from simple, but real data sets. Maybe some time in the future I will extend it to work with synthetic data, but I thought that to begin with working with data in the wild might be more convincing. Section 0 loads the required packages. Section 1 provides access to three data sets that all come from R packages. These are very simple data sets that consist of two numeric features and a column of labels: the bare minimum to fit a classification model. Section 2 is where the one of the three current data sets gets selected. If you copy the code to run on your own computer it will be obvious how to select a data set. Section 3 develops the `tidymodels` workflows. Section 4 fits the classifiers and plots the results. Section 5 computes the smoothed curves.


### Section 0: Load the Required Packages

```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show the packages required"
library(tidymodels) # For modeling and evaluation
library(dplyr)    # For data manipulation
library(ggplot2)  # For plotting
library(MASS) # for Pima.tr
library(mlbench) # for data
library(broom)
library(pROC)  # For ROC curve analysis
library(patchwork)
tidymodels_prefer()

```


### Section 1: The available data sets

In this section I have three suitable data sets from R packages and put the data, abstracted just two features and put them in a form suitable for some simple tidy modeling.
```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show Code"
# Load a sample dataset (e.g., `two_class_dat` from `modeldata`)
data(two_class_dat, package = "modeldata")
two_class_dat2 <- two_class_dat %>%  mutate(Class = recode(Class,
                           "Class1" = "1",
                           "Class2" = "2"))

data(Pima.tr, package = "MASS")
Pima.tr2 <- Pima.tr %>% mutate(
                              Class = type,
                              Class = recode(Class,
                              "Yes" = "2",
                              "No" = "1")) %>%
                        select(c(bmi,bp,Class))

data(aSAH, package = "pROC")
aSAH2 <- aSAH %>% mutate(
                              Class = outcome,
                              Class = recode(Class,
                              "Good" = "1",
                              "Poor" = "2")) %>%
                        select(c(s100b,ndka,Class))

```

### SECTION 2: Select a Data Set

The code in this section selects one of the data sets and prepares it for classification. For this post I am running the aSAH2 data set from the `pROC` package. You can see the that aSAH2 has two features and the label column `Class`. I have limited the data to two feature data sets because they show the minimum viable model and it makes constructing the tidy workflows to process the data suitable for my level of coding skills.

```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show Code"
# Set a seed for reproducibility
set.seed(123)

# Select a data set

#df<- two_class_dat2 # try FPC = 1, FNC = 10
#df <- Pima.tr2 # try FPC = 10 , FNC = 1
df <- aSAH2 #try FPC = 1, FNC = 1
head(df)

# Split the data into training and testing sets
data_split <- initial_split(df, prop = 0.75, strata = Class)
train_data <- training(data_split)
test_data <- testing(data_split)

```



### Section 3: The `tidymodels` workflows.

The workflows use three classifiers to fit the models: logistic regression, SVM, and decision tree.

```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show Code"
# Define the models

# 1. Logistic Regression
log_reg_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# 2. Support Vector Machine (SVM)
svm_spec <- svm_linear() %>%
  set_engine("kernlab") %>%
  set_mode("classification")

# 3. Decision Tree
tree_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

# Create workflows for each model
log_reg_wf <- workflow() %>%
  add_model(log_reg_spec) %>%
  add_formula(Class ~ .)

svm_wf <- workflow() %>%
  add_model(svm_spec) %>%
  add_formula(Class ~ .)

tree_wf <- workflow() %>%
  add_model(tree_spec) %>%
  add_formula(Class ~ .)

# Fit the models to the training data
log_reg_fit <- fit(log_reg_wf, data = train_data)
svm_fit <- fit(svm_wf, data = train_data)
tree_fit <- fit(tree_wf, data = train_data)

# Collect predictions for each model on the test data
log_reg_preds <- predict(log_reg_fit, new_data = test_data, type = "prob") %>%
  bind_cols(test_data %>% select(Class)) %>%
  mutate(model = "Logistic Regression")

svm_preds <- predict(svm_fit, new_data = test_data, type = "prob") %>%
  bind_cols(test_data %>% select(Class)) %>%
  mutate(model = "SVM")

tree_preds <- predict(tree_fit, new_data = test_data, type = "prob") %>%
  bind_cols(test_data %>% select(Class)) %>%
  mutate(model = "Decision Tree")

# Compute AUCs and relabel models with AUC values
auc_tree <- roc_auc(tree_preds, truth = Class, .pred_1)$.estimate
auc_svm <- roc_auc(svm_preds, truth = Class, .pred_1)$.estimate
auc_log_reg <- roc_auc(log_reg_preds, truth = Class, .pred_1)$.estimate

# Update model labels to include AUC
log_reg_preds <- log_reg_preds %>%
  mutate(model = paste0("Logistic Regression (AUC = ", round(auc_log_reg, 3), ")"))

svm_preds <- svm_preds %>%
  mutate(model = paste0("SVM (AUC = ", round(auc_svm, 3), ")"))

tree_preds <- tree_preds %>%
  mutate(model = paste0("Decision Tree (AUC = ", round(auc_tree, 3), ")"))

# Combine predictions with updated labels
all_preds <- bind_rows(log_reg_preds, svm_preds, tree_preds)
```

### Secton 4: Fit the classifiers, calculate AUC, and plot stair-step curves.
```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show Code"
### Plot the ROC Curves

 all_preds %>%
   group_by(model) %>%
  roc_curve(truth = Class, .pred_1) %>%
  autoplot() +
  labs(
    title = "ROC Curves for Multiple Classifiers",
    color = "Model"
  ) 


# Make a copy of all_preds with cleaned model names
all_preds_2 <- all_preds %>%
    mutate(model_AUC = model,
              model= sub(" \\(AUC.*$", "", model_AUC))


# Compute ROC data for each model
roc_data <- all_preds_2 %>%
  group_by(model) %>%
  roc_curve(truth = Class, .pred_1)

# Compute AUC for each model
auc_data <- all_preds_2 %>%
  group_by(model) %>%
  roc_auc(truth = Class, .pred_1)

# Inspect actual model names
#print(unique(roc_data$model))

# Build legend labels with AUC
legend_labels <- paste0(auc_data$model,
                        " (AUC = ", sprintf("%.3f", auc_data$.estimate), ")")

# IMPORTANT: match colors to the actual values in your data
# Replace the strings below with the exact output from unique(roc_data$model)
color_values <- c(
  "Logistic Regression" = "#1b9e77",
  "SVM"                 = "#7570b3",
  "Decision Tree"       = "#d95f02"
)


# Ensure model is a factor with levels matching auc_data$model
roc_data <- roc_data %>%
  mutate(model = factor(model, levels = auc_data$model))

# Plot raw step-function ROC curves
#gplot(roc_data, aes(x = 1 - specificity, y = sensitivity, color = model)) +
  # geom_path(size = 1.4) +
  # geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey50") +
  # coord_fixed(ratio = 1, xlim = c(0,1), ylim = c(0,1), expand = FALSE) +
  # labs(title = "ROC Curves for Multiple Classifiers",
  #      x = "False Positive Rate (FPR)",
  #      y = "True Positive Rate (TPR)",
  #      color = NULL) +
  # scale_color_manual(values = color_values, labels = legend_labels) +
  # #theme_classic() +
  # theme(
  #   legend.position = c(0.65, 0.25),
  #   legend.text = element_text(size = 9, lineheight = 1.1),
  #   legend.background = element_rect(fill = alpha("white", 0.7), color = NA),
  #   plot.margin = margin(20, 20, 20, 20)
  # )

```

### Section 5: Construct the Smooth Curves and Compute AUC and Arc Length.

AUC is computed for both raw and smoothed ROC curves. Arc length is only computed for the smoothed curves.

#### The computations
```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show Code"

df <- all_preds
trapz <- function(x, y) {
  sum((y[-1] + y[-length(y)]) / 2 * diff(x))
}

discrete_roc <- function(df) {
  roc_obj <- roc(response = df$Class,
                 predictor = df$.pred_1,
                 levels = c("2","1"),   # control first, positive second
                 direction = "<")
  
  rc <- coords(roc_obj, "all", ret = c("specificity","sensitivity"), transpose = FALSE)
  FPR <- 1 - rc$specificity
  TPR <- rc$sensitivity
  
  FPR <- c(0, FPR, 1)
  TPR <- c(0, TPR, 1)
  ord <- order(FPR, TPR)
  FPR <- FPR[ord]
  TPR <- cummax(TPR[ord])   # enforce monotonicity
  
  tibble(FPR = FPR, TPR = TPR)
}

smooth_roc <- function(FPR, TPR, n = 400) {
  df <- tibble(FPR = FPR, TPR = TPR) %>% arrange(FPR) %>% distinct(FPR, .keep_all = TRUE)
  mono_fun <- splinefun(x = df$FPR, y = df$TPR, method = "monoH.FC")
  x <- seq(0, 1, length.out = n)
  y <- pmin(pmax(mono_fun(x), 0), 1)
  
  auc <- trapz(x, y)
  dy <- mono_fun(x, deriv = 1)
  arc <- trapz(x, sqrt(1 + dy^2))
  
  tibble(FPR = x, TPR = y, auc = auc, arc = arc)
}

# Normalize model names
 df <- df %>%
  mutate(model_norm = sub(" \\(.*$", "", model))

smooth_results <- df %>%
  group_by(model_norm) %>%
  group_modify(~ {
    dr <- discrete_roc(.x)
    sr <- smooth_roc(dr$FPR, dr$TPR, n = 400)
    #sr %>% mutate(model_norm = unique(.x$model_norm))
  }) %>%
  ungroup()

metrics <- smooth_results %>%
  group_by(model_norm) %>%
  summarise(AUC = unique(auc), Arc = unique(arc), .groups = "drop")

# legend_labels <- setNames(
#   paste0(metrics$model_norm, "\nAUC = ", sprintf("%.3f", metrics$AUC),
#          "\nArc = ", sprintf("%.3f", metrics$Arc)),
#   metrics$model_norm
# )
# 
# color_values <- setNames(
#   c( "#d95f02", "#1b9e77","#7570b3"),
#   unique(metrics$model_norm)
# )
# 
# p_smooth <- ggplot(smooth_results, aes(x = FPR, y = TPR, color = model_norm)) +
#   geom_line(linewidth = 1.4) +
#   geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey50") +
#   coord_fixed(ratio = 1, xlim = c(0,1), ylim = c(0,1), expand = FALSE) +  # square plot
#   labs(title = "Smoothed ROC curves by model",
#        x = "False positive rate (FPR)",
#        y = "True positive rate (TPR)",
#        color = NULL) +
#   scale_color_manual(values = color_values, labels = legend_labels) +
#   #theme_minimal(base_size = 16) +
#   theme(
#     legend.position.inside = c(0.65, 0.25),   # inside plot, under diagonal
#     legend.text = element_text(size = 9, lineheight = 1.1),
#     legend.background = element_rect(fill = alpha("white", 0.7), color = NA),
#     plot.margin = margin(20, 20, 20, 20)
#   )
# p_smooth
```



#### The over plot

```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show Code"

# df_raw: columns .pred_1, .pred_2, Class, model
# smooth_results: columns model_norm, FPR, TPR, auc, arc

# 1) Normalize model names in the raw data so they match smooth_results$model_norm
df_raw <- all_preds %>%
  mutate(model_norm = sub(" \\(.*$", "", model))  # e.g., "Logistic Regression (AUC = ...)" -> "Logistic Regression"

# 2) Compute raw ROC coordinates and raw AUC per model
raw_results <- df_raw %>%
  group_by(model_norm) %>%
  group_map(~{
    roc_obj <- roc(response = .x$Class,
                   predictor = .x$.pred_1,
                   levels = c("2","1"),
                   direction = "<")

    rc <- coords(roc_obj, "all", ret = c("specificity","sensitivity"), transpose = FALSE)
    FPR <- 1 - rc$specificity
    TPR <- rc$sensitivity

    # pad ends, order, enforce monotone TPR
    FPR <- c(0, FPR, 1)
    TPR <- c(0, TPR, 1)
    ord <- order(FPR, TPR)
    FPR <- FPR[ord]
    TPR <- cummax(TPR[ord])

    auc_raw <- as.numeric(auc(roc_obj))
    m <- .y$model_norm[[1]]  # group label; safer than looking back into .x

    tibble(
      model_norm = rep(m, length(FPR)),
      FPR = FPR,
      TPR = TPR,
      auc_raw = rep(auc_raw, length(FPR)),
      curve_type = rep("raw", length(FPR))
    )
  }) %>%
  bind_rows()

# 3) Prepare smoothed results to match columns (add curve_type and placeholder auc_raw)
smooth_results_plot <- smooth_results %>%
  mutate(
    curve_type = "smooth",
    auc_raw = NA_real_  # placeholder so bind_rows columns align
  )

# 4) Combine raw + smooth results
roc_results <- bind_rows(raw_results, smooth_results_plot)

# 5) Build legend metrics: Raw AUC (from raw_results), Smooth AUC and Arc (from smooth_results)
metrics_raw <- raw_results %>%
  distinct(model_norm, auc_raw) %>%
  rename(AUC_raw = auc_raw)

metrics_smooth <- smooth_results %>%
  distinct(model_norm, auc, arc) %>%
  rename(AUC_smooth = auc, Arc = arc)

metrics <- metrics_raw %>%
  left_join(metrics_smooth, by = "model_norm")

legend_labels <- setNames(
  paste0(metrics$model_norm,
         "\nRaw AUC = ", sprintf("%.3f", metrics$AUC_raw),
         "\nSmooth AUC = ", sprintf("%.3f", metrics$AUC_smooth),
         "\nArc = ", sprintf("%.3f", metrics$Arc)),
  metrics$model_norm
)

# 6) Pastel colors (keep model association). Ensure names match smooth_results$model_norm exactly.
color_values <- c(
  "Decision Tree"        = "#fcae91",  # pastel red
  "Logistic Regression"  = "#a1d99b",  # pastel green
  "SVM"                  = "#9ecae1"   # pastel blue
)



legend_labels <- setNames(
  paste0(metrics$model_norm,
         "\nRaw AUC = ", sprintf("%.3f", metrics$AUC_raw),
         " | Smooth AUC = ", sprintf("%.3f", metrics$AUC_smooth),
         "\nArc = ", sprintf("%.3f", metrics$Arc),
         "\n"),   # blank line between models
  metrics$model_norm
)

ggplot(roc_results, aes(x=FPR, y=TPR,
                        color=model_norm,
                        linetype=curve_type)) +
  geom_line(linewidth=1) +
  geom_abline(slope=1, intercept=0,
              linetype="dashed", color="grey60") +
  scale_color_manual(values=color_values, labels=legend_labels) +
  scale_linetype_manual(
    values = c("raw"="dashed", "smooth"="solid"),
    labels = c("raw"="Raw ROC: dashed", "smooth"="Smoothed ROC: solid")
  ) +
  scale_x_continuous(limits=c(0,1), expand=c(0,0)) +
  scale_y_continuous(limits=c(0,1), expand=c(0,0)) +
  labs(title="ROC curves by model (raw vs smoothed)",
       x="False Positive Rate",
       y="True Positive Rate",
       color=NULL, linetype=NULL) +
  guides(
    color = guide_legend(order = 1, title = NULL, label.theme = element_text(size = 7)),
    linetype = guide_legend(order = 2, title = NULL, label.theme = element_text(size = 7))
  ) +
  theme_minimal(base_size=10) +
  theme(
    plot.title = element_text(size=9, face="bold"),
    axis.title = element_text(size=8),
    axis.text  = element_text(size=7),
    legend.position = c(0.65, 0.25),   # inside plot, under diagonal
    legend.text = element_text(size=7, lineheight=1.2),
    legend.background = element_rect(fill = alpha("white", 0.8), color = NA),
    legend.key.size = unit(0.5, "lines"),
    plot.margin = margin(2, 2, 2, 2)
  )


```

The first thing to observe that the smooth curves do not perfectly overlay the stair-step curves, as one might expect for curves with large steps. Nevertheless the AUC numbers are close, and in this case they preserve the order. Also note that selecting the curves passed on arc length would lead to the same results.


#### The Case for Arc Length

The main insight is that ROC curve is the direct representation of the conditional probability distribution related to True Positive Rate (TPR) and False Positive Rate (FPR). Each point (x,y) on the ROC curve yields the conditional distribution of TPR given the distribution of FPR. $P(TPR \le y \mid FPR \le x)$. This a direct, and to my mind clear, probability statement. AUC, on the other hand, is an indirect measure with the probability interpretation usually rendered something like the definition provided in [wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#:~:text=The%20area%20under%20the%20curve,ranks%20higher%20than%20'negative')

>"AUC is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one (assuming 'positive' ranks higher than 'negative')'. 

I have never seen this observation being used to support a practical analysis of ROC curves. Moreover, is also the case that arc length is a linear measure while AUC is an area. I may very well be be wrong about this, but I think most people have a better intuition of the practical significance of a linear difference of 0.3 inches than an area difference of 0.3 square inches.

Arc length also mostly avoids the criticism of AUC that led to the development of [Partial Arc length](https://en.wikipedia.org/wiki/Partial_Area_Under_the_ROC_Curve). It is relatively easy to exclude segments of regions that are not important to the application. Finally, arc length is directly related to the geometry of the ROC curve and some basic ideas of differential geometry may be useful in interpreting the behavior of ROC curves.

### Table Comparing Arclength with AUC 

| Aspect                        | AUC (Area Under Curve)                                                                 | Arc Length (ROC Curve Length)                                                                 |
|-------------------------------|-----------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------|
| **Definition**                | Integral of TPR over FPR: $\int_0^1 f(x)\,dx$                                        | Integral of curve length: $\int_0^1 \sqrt{1+(f'(x))^2}\,dx$                                  |
| **Probabilistic meaning**     | Probability that a randomly chosen positive is ranked above a randomly chosen negative | Probability that TPR ≤ y given FPR ≤ x (joint distribution along ROC trajectory)               |
| **Bounds**                    | 0.5 (random) to 1.0 (perfect)                                                          | $\sqrt{2} \approx 1.414$ (diagonal) to 2.0 (perfect staircase ROC)                           |
| **Interpretability**          | Widely used, intuitive for clinicians; benchmarks exist (e.g., >0.9 = excellent)        | Linear measure, easier to visualize by eye; highlights curve geometry and trajectory           |
| **Sensitivity to curve shape**| Less sensitive — curves with different shapes can yield similar AUC                     | More sensitive — captures slope changes, curvature, and smoothness differences                 |
| **Partial evaluation**        | Partial AUC requires normalization; less visually obvious                               | It is easy to avoid problematic regions for most reasonable ROC curves                        |
| **Noise robustness**          | Relatively robust; integrates over curve                                                | More sensitive to noise or jaggedness; small oscillations inflate length                       |
| **Clinical adoption**         | Standard metric with established thresholds                                             | Novel metric; not yet widely adopted, requires new benchmarks                                  |
| **Use cases**                 | Ranking accuracy, overall discrimination power                                          | Diagnostic trajectory, geometric comparison, highlighting regional performance differences     |






## The Relevance of Calculus to ROC Curves

This next plot shows the ROC curves for the three classifiers in the left column and the derivative of TPR with respect to FPR, $d(TPR) / d(FPR)$ in the right hand column for each classifier showing how the slopes of the ROC curves as FPR increases. To build this plot splines build TPR as a function of FPR and derivatives are computed with with respect to FPR.


```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show the code for computing slope"
# --- Palette: pastel per model ---
model_colors <- c(
  "Decision Tree"       = "#F28E8E",  # pastel red
  "Logistic Regression" = "#8FD19E",  # pastel green
  "SVM"                 = "#8EB8FF"   # pastel blue
)

# --- Clean ROC per group: sort, drop duplicate FPR, enforce monotone TPR ---
clean_roc <- function(df) {
  df %>%
    arrange(FPR) %>%
    distinct(FPR, .keep_all = TRUE) %>%
    mutate(
      FPR = pmin(pmax(FPR, 0), 1),
      TPR = pmin(pmax(cummax(TPR), 0), 1)
    )
}

# --- Spline builder (use "natural" to avoid strict monotonicity errors) ---
make_spline <- function(df) {
  df <- clean_roc(df)
  splinefun(x = df$FPR, y = df$TPR, method = "natural")
}

# --- Geometry over a uniform grid: y, y', y'' ---
compute_roc_geometry <- function(df, n_grid = 1001) {
  f <- make_spline(df)
  xg  <- seq(0, 1, length.out = n_grid)
  yg  <- f(xg, deriv = 0)
  y1g <- f(xg, deriv = 1)
  y2g <- f(xg, deriv = 2)
  tibble(FPR = xg, TPR = yg, dTPR = y1g, d2TPR = y2g)
}


# --- Plotters with small text and single-color line per model ---
plot_roc <- function(geom_df, model_label, color_hex) {
  ggplot(geom_df, aes(x = FPR, y = TPR)) +
    geom_line(color = color_hex, linewidth = 0.9) +
    labs(
      title = paste(model_label, "— Smoothed ROC"),
      x = "FPR",
      y = "TPR"
    ) +
    coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +
    theme_minimal(base_size = 9) +
    theme(
      plot.title = element_text(face = "bold", size = 9),
      axis.title = element_text(size = 8),
      axis.text  = element_text(size = 8),
      panel.grid.minor = element_blank()
    )
}

plot_derivative <- function(geom_df, model_label, color_hex) {
  ggplot(geom_df, aes(x = FPR, y = dTPR)) +
    geom_hline(yintercept = 0, color = "grey80") +
    geom_line(color = color_hex, linewidth = 0.9) +
    labs(
      title = paste(model_label, "— dTPR/dFPR vs FPR"),
      x = "FPR",
      y = "dTPR/dFPR"
    ) +
    coord_cartesian(xlim = c(0, 1)) +
    theme_minimal(base_size = 9) +
    theme(
      plot.title = element_text(face = "bold", size = 9),
      axis.title = element_text(size = 8),
      axis.text  = element_text(size = 8),
      panel.grid.minor = element_blank()
    )
}

# --- Main: build 3x2 grid with ROC on the LEFT, derivative on the RIGHT ---
plot_roc_geometry_grid <- function(smooth_results, n_grid = 1001) {
  # Ensure intended order of rows
  model_order <- c("Decision Tree", "Logistic Regression", "SVM")
  models <- intersect(model_order, unique(smooth_results$model_norm))
  stopifnot(length(models) > 0)

  rows <- map(models, function(m) {
    df <- smooth_results %>% filter(model_norm == m)
    geom_df <- compute_roc_geometry(df, n_grid)
    col_hex <- model_colors[[m]]
    p_left  <- plot_roc(geom_df, m, col_hex)
    p_right <- plot_derivative(geom_df, m, col_hex)
    p_left | p_right
  })

  # Stack rows into 3x2 (or as many as available)
  reduce(rows, `/`)
}

# --- Usage ---
# smooth_results must have columns: model_norm, FPR, TPR
grid_plot <- plot_roc_geometry_grid(smooth_results, n_grid = 2001)
print(grid_plot)

```

However, a well known result from mathematical statistics not usually emphasized in a machine learning context is that the slope of the tangent to the ROC curve at any point is equal to the the instantaneous likelihood ratio at that point. [Choi (1998)](https://academic.oup.com/aje/article-abstract/148/11/1127/123231?redirectedFrom=PDF). To understand this result it is best to take the differential geometry view and consider ROC curves as parametric curves of points $(FPR(t),TPR(t))$ where the threshold, $t$, is the parameter. This point of view is preferred for analyzing likelihood ratios and connecting with diagnostic test theory. In both cases the likelihood ratio is identical since likelihood is a property of the curve and $d(TPR)/d(FPR) = \frac{d(TPR)/dt))}{d(FPR)/dt}$


```{r}
#| message: FALSE
#| warning: FALSE
#| code-fold: TRUE
#| code-summary: "Show the code for parameterized ROC curves"

# --- Pastel palette per model ---
model_colors <- c(
  "Decision Tree"       = "#F28E8E",  # pastel red
  "Logistic Regression" = "#8FD19E",  # pastel green
  "SVM"                 = "#8EB8FF"   # pastel blue
)

# --- Ensure threshold column exists ---
add_threshold <- function(df) {
  df %>%
    group_by(model_norm) %>%
    mutate(threshold = seq(0, 1, length.out = n())) %>%
    ungroup()
}

# --- Clean ROC per group ---
clean_roc <- function(df) {
  df %>%
    arrange(threshold) %>%
    distinct(threshold, .keep_all = TRUE) %>%
    mutate(
      FPR = pmin(pmax(FPR, 0), 1),
      TPR = pmin(pmax(TPR, 0), 1)
    )
}

# --- Spline builders for parametric ROC (FPR(t), TPR(t)) ---
make_spline_pair <- function(df) {
  df <- clean_roc(df)
  f_fpr <- splinefun(x = df$threshold, y = df$FPR, method = "natural")
  f_tpr <- splinefun(x = df$threshold, y = df$TPR, method = "natural")
  list(f_fpr = f_fpr, f_tpr = f_tpr)
}

# --- Compute ROC geometry with respect to threshold t ---
compute_roc_geometry <- function(df, n_grid = 1001) {
  spl <- make_spline_pair(df)
  f_fpr <- spl$f_fpr
  f_tpr <- spl$f_tpr

  tg <- seq(min(df$threshold), max(df$threshold), length.out = n_grid)

  x   <- f_fpr(tg, deriv = 0)   # FPR(t)
  y   <- f_tpr(tg, deriv = 0)   # TPR(t)
  x1  <- f_fpr(tg, deriv = 1)   # dFPR/dt
  y1  <- f_tpr(tg, deriv = 1)   # dTPR/dt

  # slope of ROC curve = dTPR/dFPR = (dTPR/dt) / (dFPR/dt)
  slope <- y1 / x1

  tibble(
    threshold = tg,
    FPR = x,
    TPR = y,
    dFPR_dt = x1,
    dTPR_dt = y1,
    slope_dTPR_dFPR = slope
  )
}

# --- Build combined data frame for all models ---
make_derivative_df <- function(smooth_results, n_grid = 1001) {
  smooth_results <- add_threshold(smooth_results)

  model_order <- c("Decision Tree", "Logistic Regression", "SVM")
  models <- intersect(model_order, unique(smooth_results$model_norm))

  results <- map_dfr(models, function(m) {
    df <- smooth_results %>% filter(model_norm == m)
    geom_df <- compute_roc_geometry(df, n_grid)
    geom_df %>% mutate(model = m)
  })

  results
}

# --- Plotters ---
plot_curvature <- function(geom_df, model_label, color_hex) {
  ggplot(geom_df, aes(x = threshold, y = TPR)) +
    geom_line(color = color_hex, linewidth = 0.9) +
    labs(title = paste(model_label, "— ROC curve TPR(t)"),
         x = "Threshold", y = "TPR") +
    theme_minimal(base_size = 9) +
    theme(plot.title = element_text(face = "bold", size = 9),
          axis.title = element_text(size = 8),
          axis.text  = element_text(size = 8),
          panel.grid.minor = element_blank())
}

plot_slope <- function(geom_df, model_label, color_hex) {
  ggplot(geom_df, aes(x = threshold, y = slope_dTPR_dFPR)) +
    geom_hline(yintercept = 0, color = "grey80") +
    geom_line(color = color_hex, linewidth = 0.9) +
    labs(title = paste(model_label, "— dTPR/dFPR (Likelihood Ratio)"),
         x = "Threshold", y = "dTPR/dFPR") +
    theme_minimal(base_size = 9) +
    theme(plot.title = element_text(face = "bold", size = 9),
          axis.title = element_text(size = 8),
          axis.text  = element_text(size = 8),
          panel.grid.minor = element_blank())
}

# --- Main: build 3x2 grid (ROC curve | slope dTPR/dFPR) ---
plot_roc_geometry_grid <- function(smooth_results, n_grid = 1001) {
  smooth_results <- add_threshold(smooth_results)

  model_order <- c("Decision Tree", "Logistic Regression", "SVM")
  models <- intersect(model_order, unique(smooth_results$model_norm))
  stopifnot(length(models) > 0)

  rows <- map(models, function(m) {
    df <- smooth_results %>% filter(model_norm == m)
    geom_df <- compute_roc_geometry(df, n_grid)
    col_hex <- model_colors[[m]]
    p_left  <- plot_curvature(geom_df, m, col_hex)
    p_right <- plot_slope(geom_df, m, col_hex)
    patchwork::wrap_plots(p_left, p_right, ncol = 2)
  })

  reduce(rows, `/`)
}

# --- Usage ---
derivative_df <- make_derivative_df(smooth_results, n_grid = 2001)
grid_plot <- plot_roc_geometry_grid(smooth_results, n_grid = 2001)

print(grid_plot)
head(derivative_df)

```

## Curvature

The curvature, $\kappa(t)$ of an ROC curve measures how sharply the curve bends at a given threshold, $t$. High curvature implies rapidly changing slope while low curvature indicates the slope is changing slowly. The derivative of curvature indicates how fast the changing slope itself is changing. Large positive values of $dk/dt$ can indicate threshold zone where small changes in the decision rule can produce large changes in discrimination. Large negative values of $dk/dt$ can indicate zones where slope changes are stabilizing suggesting diminishing returns for tightening or loosening the decision rules. Zones whith values near zero idicate regions that are relatively stable with respect of threshold.

## New Code

```{r}
library(dplyr)
library(ggplot2)
library(purrr)
library(patchwork)
library(tibble)

# --- Pastel palette per model ---
model_colors <- c(
  "Decision Tree"       = "#F28E8E",  # pastel red
  "Logistic Regression" = "#8FD19E",  # pastel green
  "SVM"                 = "#8EB8FF"   # pastel blue
)

# --- Ensure threshold column exists ---
# If smooth_results has only FPR/TPR, add a synthetic threshold
add_threshold <- function(df) {
  df %>%
    group_by(model_norm) %>%
    mutate(threshold = seq(0, 1, length.out = n())) %>%
    ungroup()
}

# --- Clean ROC per group ---
clean_roc <- function(df) {
  df %>%
    arrange(threshold) %>%
    distinct(threshold, .keep_all = TRUE) %>%
    mutate(
      FPR = pmin(pmax(FPR, 0), 1),
      TPR = pmin(pmax(TPR, 0), 1)
    )
}

# --- Spline builders for parametric ROC (FPR(t), TPR(t)) ---
make_spline_pair <- function(df) {
  df <- clean_roc(df)
  f_fpr <- splinefun(x = df$threshold, y = df$FPR, method = "natural")
  f_tpr <- splinefun(x = df$threshold, y = df$TPR, method = "natural")
  list(f_fpr = f_fpr, f_tpr = f_tpr)
}

# --- Compute ROC geometry with respect to threshold t ---
compute_roc_geometry <- function(df, n_grid = 1001) {
  spl <- make_spline_pair(df)
  f_fpr <- spl$f_fpr
  f_tpr <- spl$f_tpr

  tg <- seq(min(df$threshold), max(df$threshold), length.out = n_grid)

  x   <- f_fpr(tg, deriv = 0)
  y   <- f_tpr(tg, deriv = 0)
  x1  <- f_fpr(tg, deriv = 1)
  y1  <- f_tpr(tg, deriv = 1)
  x2  <- f_fpr(tg, deriv = 2)
  y2  <- f_tpr(tg, deriv = 2)
  x3  <- f_fpr(tg, deriv = 3)
  y3  <- f_tpr(tg, deriv = 3)

  # curvature κ(t)
  num   <- x1 * y2 - y1 * x2
  denom <- (x1^2 + y1^2)^(3/2)
  kappa <- abs(num) / denom

  # derivative of curvature wrt t
  dnum   <- x1 * y3 - y1 * x3 + x2 * y2 - y2 * x2
  ddenom <- (3/2) * (x1^2 + y1^2)^(1/2) * (2*x1*x2 + 2*y1*y2)
  dkappa_dt <- (dnum * denom - num * ddenom) / (denom^2)

  tibble(
    threshold = tg,
    FPR = x,
    TPR = y,
    dFPR_dt = x1,
    dTPR_dt = y1,
    kappa = kappa,
    dkappa_dt = dkappa_dt
  )
}

# --- Build combined data frame for all models ---
make_derivative_df <- function(smooth_results, n_grid = 1001) {
  smooth_results <- add_threshold(smooth_results)

  model_order <- c("Decision Tree", "Logistic Regression", "SVM")
  models <- intersect(model_order, unique(smooth_results$model_norm))

  results <- map_dfr(models, function(m) {
    df <- smooth_results %>% filter(model_norm == m)
    geom_df <- compute_roc_geometry(df, n_grid)
    geom_df %>% mutate(model = m)
  })

  results
}

# --- Plotters ---
plot_curvature <- function(geom_df, model_label, color_hex) {
  ggplot(geom_df, aes(x = threshold, y = kappa)) +
    geom_line(color = color_hex, linewidth = 0.9) +
    labs(title = paste(model_label, "— curvature κ(t)"),
         x = "Threshold", y = "κ(t)") +
    theme_minimal(base_size = 9) +
    theme(plot.title = element_text(face = "bold", size = 9),
          axis.title = element_text(size = 8),
          axis.text  = element_text(size = 8),
          panel.grid.minor = element_blank())
}

plot_dcurvature <- function(geom_df, model_label, color_hex) {
  ggplot(geom_df, aes(x = threshold, y = dkappa_dt)) +
    geom_hline(yintercept = 0, color = "grey80") +
    geom_line(color = color_hex, linewidth = 0.9) +
    labs(title = paste(model_label, "— dκ/dt"),
         x = "Threshold", y = "dκ/dt") +
    theme_minimal(base_size = 9) +
    theme(plot.title = element_text(face = "bold", size = 9),
          axis.title = element_text(size = 8),
          axis.text  = element_text(size = 8),
          panel.grid.minor = element_blank())
}

# --- Main: build 3x2 grid (curvature | dκ/dt) ---
plot_roc_geometry_grid <- function(smooth_results, n_grid = 1001) {
  smooth_results <- add_threshold(smooth_results)

  model_order <- c("Decision Tree", "Logistic Regression", "SVM")
  models <- intersect(model_order, unique(smooth_results$model_norm))
  stopifnot(length(models) > 0)

  rows <- map(models, function(m) {
    df <- smooth_results %>% filter(model_norm == m)
    geom_df <- compute_roc_geometry(df, n_grid)
    col_hex <- model_colors[[m]]
    p_left  <- plot_curvature(geom_df, m, col_hex)
    p_right <- plot_dcurvature(geom_df, m, col_hex)
    patchwork::wrap_plots(p_left, p_right, ncol = 2)
  })

  reduce(rows, `/`)
}

# --- Usage ---
derivative_df <- make_derivative_df(smooth_results, n_grid = 2001)
grid_plot <- plot_roc_geometry_grid(smooth_results, n_grid = 2001)

print(grid_plot)
head(derivative_df)

```


### Phase Space Plots

Notes for interpretation
Curve direction: The path is traced as threshold t increases; it shows how the ROC’s bending (κ) and its rate of change (dκ/dt) co‑evolve.

Large |dκ/dt|: Indicates thresholds where ROC geometry changes rapidly; these are sensitive operating regions.

Sign of dκ/dt: Positive means curvature is increasing with t; negative means curvature is decreasing with t.

Per‑model trajectories: Overlaid paths help you compare how each model’s ROC geometry transitions across thresholds.
```{r}
library(dplyr)
library(ggplot2)
library(purrr)
library(patchwork)
library(tibble)

# --- Pastel palette per model ---
model_colors <- c(
  "Decision Tree"       = "#F28E8E",  # pastel red
  "Logistic Regression" = "#8FD19E",  # pastel green
  "SVM"                 = "#8EB8FF"   # pastel blue
)

# --- Ensure threshold column exists (uniform per model) ---
add_threshold <- function(df) {
  df %>%
    group_by(model_norm) %>%
    mutate(threshold = seq(0, 1, length.out = n())) %>%
    ungroup()
}

# --- Clean ROC per group (threshold-ordered, bounded) ---
clean_roc <- function(df) {
  df %>%
    arrange(threshold) %>%
    distinct(threshold, .keep_all = TRUE) %>%
    mutate(
      FPR = pmin(pmax(FPR, 0), 1),
      TPR = pmin(pmax(TPR, 0), 1)
    )
}

# --- Spline builders for parametric ROC (FPR(t), TPR(t)) ---
make_spline_pair <- function(df) {
  df <- clean_roc(df)
  f_fpr <- splinefun(x = df$threshold, y = df$FPR, method = "natural")
  f_tpr <- splinefun(x = df$threshold, y = df$TPR, method = "natural")
  list(f_fpr = f_fpr, f_tpr = f_tpr)
}

# --- Compute curvature κ(t) and dκ/dt with respect to threshold t ---
compute_roc_geometry <- function(df, n_grid = 1001) {
  spl <- make_spline_pair(df)
  f_fpr <- spl$f_fpr
  f_tpr <- spl$f_tpr

  tg <- seq(min(df$threshold), max(df$threshold), length.out = n_grid)

  x   <- f_fpr(tg, deriv = 0)   # FPR(t)
  y   <- f_tpr(tg, deriv = 0)   # TPR(t)
  x1  <- f_fpr(tg, deriv = 1)   # dFPR/dt
  y1  <- f_tpr(tg, deriv = 1)   # dTPR/dt
  x2  <- f_fpr(tg, deriv = 2)   # d2FPR/dt2
  y2  <- f_tpr(tg, deriv = 2)   # d2TPR/dt2
  x3  <- f_fpr(tg, deriv = 3)   # d3FPR/dt3
  y3  <- f_tpr(tg, deriv = 3)   # d3TPR/dt3

  # curvature κ(t) for parametric curve (x(t), y(t))
  num   <- x1 * y2 - y1 * x2
  denom <- (x1^2 + y1^2)^(3/2)
  kappa <- abs(num) / denom

  # derivative of curvature wrt t: dκ/dt
  # d/dt [ |num| / denom ] = sign(num) * (dnum*denom - num*ddenom) / denom^2
  # where sign(num) = ifelse(num >= 0, 1, -1)
  sign_num <- ifelse(num >= 0, 1, -1)
  dnum     <- (x1 * y3 - y1 * x3) + (x2 * y2 - y2 * x2)
  ddenom   <- (3/2) * (x1^2 + y1^2)^(1/2) * (2*x1*x2 + 2*y1*y2)
  dkappa_dt <- sign_num * (dnum * denom - num * ddenom) / (denom^2)

  # likelihood ratio slope dTPR/dFPR (for reference/overlay if needed)
  slope <- y1 / x1

  tibble(
    threshold = tg,
    FPR = x,
    TPR = y,
    dFPR_dt = x1,
    dTPR_dt = y1,
    kappa = kappa,
    dkappa_dt = dkappa_dt,
    slope_dTPR_dFPR = slope
  )
}

# --- Build unified derivatives data frame across models ---
make_derivative_df <- function(smooth_results, n_grid = 1001) {
  smooth_results <- add_threshold(smooth_results)

  model_order <- c("Decision Tree", "Logistic Regression", "SVM")
  models <- intersect(model_order, unique(smooth_results$model_norm))

  map_dfr(models, function(m) {
    df <- smooth_results %>% filter(model_norm == m)
    compute_roc_geometry(df, n_grid) %>% mutate(model = m)
  })
}

# --- Phase space plot: dκ/dt (y) vs κ(t) (x) ---
plot_phase_space <- function(derivative_df) {
  ggplot(derivative_df, aes(x = kappa, y = dkappa_dt, color = model)) +
    geom_path(linewidth = 1) +
    scale_color_manual(values = model_colors) +
    labs(
      title = "Phase space of ROC curvature dynamics",
      x = "Curvature, κ(t)",
      y = "Derivative of curvature, dκ/dt",
      color = "Model"
    ) +
    theme_minimal(base_size = 10) +
    theme(
      plot.title = element_text(face = "bold", size = 11),
      axis.title = element_text(size = 10),
      axis.text  = element_text(size = 9),
      legend.position = "bottom"
    )
}

# --- Usage ---
derivative_df <- make_derivative_df(smooth_results, n_grid = 2001)
phase_plot <- plot_phase_space(derivative_df)

print(phase_plot)

```

```{r}
library(ggplot2)

plot_phase_space_facets <- function(derivative_df) {
  ggplot(derivative_df, aes(x = kappa, y = dkappa_dt, color = model)) +
    geom_path(linewidth = 1) +
    scale_color_manual(values = model_colors) +
    labs(
      title = "Phase space of ROC curvature dynamics",
      x = "Curvature, κ(t)",
      y = "Derivative of curvature, dκ/dt"
    ) +
    facet_wrap(~model, ncol = 1, scales = "fixed") +
    theme_minimal(base_size = 10) +
    theme(
      plot.title = element_text(face = "bold", size = 11),
      axis.title = element_text(size = 10),
      axis.text  = element_text(size = 9),
      legend.position = "none",   # remove legend since facets label models
      strip.text = element_text(face = "bold", size = 10)
    )
}

# --- Usage ---
derivative_df <- make_derivative_df(smooth_results, n_grid = 2001)
phase_plot_facets <- plot_phase_space_facets(derivative_df)

print(phase_plot_facets)

```


## Appendix

These are the equations for the derivatives used in the curvature calculations.

$y'(x) = \frac{d\,\text{TPR}}{d\,\text{FPR}}$

$y'(x) = \frac{d\,\text{TPR}}{d\,\text{FPR}}$

$y''(x) = \frac{d^2\,\text{TPR}}{d\,\text{FPR}^2}$

$y'''(x) = \frac{d^3\,\text{TPR}}{d\,\text{FPR}^3}$

$\kappa(x) = \frac{|y''(x)|}{\left(1 + \left[y'(x)\right]^2\right)^{3/2}}$

$\frac{d\kappa}{dx} = \frac{y'''(x)\,\left(1 + \left[y'(x)\right]^2\right) - 3\,y'(x)\,\left(y''(x)\right)^2}{\left(1 + \left[y'(x)\right]^2\right)^{5/2}}$



